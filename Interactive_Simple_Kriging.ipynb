{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/GeostatsGuy/GeostatsPy/blob/master/TCG_color_logo.png?raw=true\" width=\"220\" height=\"240\" />\n",
    "\n",
    "</p>\n",
    "\n",
    "## Interactive Simple Kriging Demonstration\n",
    "\n",
    "\n",
    "### Michael Pyrcz, Associate Professor, University of Texas at Austin \n",
    "\n",
    "##### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "\n",
    "### The Interactive Workflow\n",
    "\n",
    "Here's a simple workflow for calculating the simple kriging estimate and the estimation variance for a local uncertainty model\n",
    "\n",
    "* we use a 'toy problem' with only 3 data for speed and interpretability of the results\n",
    "\n",
    "#### Spatial Estimation\n",
    "\n",
    "Consider the case of making an estimate at some unsampled location, $ð‘§(\\bf{u}_0)$, where $z$ is the property of interest (e.g. porosity etc.) and $ð®_0$ is a location vector describing the unsampled location.\n",
    "\n",
    "How would you do this given data, $ð‘§(\\bf{ð®}_1)$, $ð‘§(\\bf{ð®}_2)$, and $ð‘§(\\bf{ð®}_3)$?\n",
    "\n",
    "It would be natural to use a set of linear weights to formulate the estimator given the available data.\n",
    "\n",
    "\\begin{equation}\n",
    "z^{*}(\\bf{u}) = \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} z(\\bf{u}_{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "We could add an unbiasedness constraint to impose the sum of the weights equal to one.  What we will do is assign the remainder of the weight (one minus the sum of weights) to the global average; therefore, if we have no informative data we will estimate with the global average of the property of interest.\n",
    "\n",
    "\\begin{equation}\n",
    "z^{*}(\\bf{u}) = \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} z(\\bf{u}_{\\alpha}) + \\left(1-\\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} \\right) \\overline{z}\n",
    "\\end{equation}\n",
    "\n",
    "We will make a stationarity assumption, so let's assume that we are working with residuals, $y$. \n",
    "\n",
    "\\begin{equation}\n",
    "y^{*}(\\bf{u}) = z^{*}(\\bf{u}) - \\overline{z}(\\bf{u})\n",
    "\\end{equation}\n",
    "\n",
    "If we substitute this form into our estimator the estimator simplifies, since the mean of the residual is zero.\n",
    "\n",
    "\\begin{equation}\n",
    "y^{*}(\\bf{u}) = \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} y(\\bf{u}_{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "while satisfying the unbaisedness constraint.  \n",
    "\n",
    "#### Kriging\n",
    "\n",
    "Now the next question is what weights should we use?  \n",
    "\n",
    "We could use equal weighting, $\\lambda = \\frac{1}{n}$, and the estimator would be the average of the local data applied for the spatial estimate. This would not be very informative.\n",
    "\n",
    "We could assign weights considering the spatial context of the data and the estimate:\n",
    "\n",
    "* **spatial continuity** as quantified by the variogram (and covariance function)\n",
    "* **redundancy** the degree of spatial continuity between all of the available data with themselves \n",
    "* **closeness** the degree of spatial continuity between the avaiable data and the estimation location\n",
    "\n",
    "The kriging approach accomplishes this, calculating the best linear unbiased weights for the local data to estimate at the unknown location.  The derivation of the kriging system and the resulting linear set of equations is available in the lecture notes.  Furthermore kriging provides a measure of the accuracy of the estimate!  This is the kriging estimation variance (sometimes just called the kriging variance).\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^{2}_{E}(\\bf{u}) = C(0) - \\sum^{n}_{\\alpha = 1} \\lambda_{\\alpha} C(\\bf{u}_0 - \\bf{u}_{\\alpha})\n",
    "\\end{equation}\n",
    "\n",
    "What is 'best' about this estimate? Kriging estimates are best in that they minimize the above estimation variance. \n",
    "\n",
    "#### Properties of Kriging\n",
    "\n",
    "Here are some important properties of kriging:\n",
    "\n",
    "* **Exact interpolator** - kriging estimates with the data values at the data locations\n",
    "* **Kriging variance** can be calculated before getting the sample information, as the kriging estimation variance is not dependent on the values of the data nor the kriging estimate, i.e. the kriging estimator is homoscedastic. \n",
    "* **Spatial context** - kriging takes into account, furthermore to the statements on spatial continuity, closeness and redundancy we can state that kriging accounts for the configuration of the data and structural continuity of the variable being estimated.\n",
    "* **Scale** - kriging may be generalized to account for the support volume of the data and estimate. We will cover this later.\n",
    "* **Multivariate** - kriging may be generalized to account for multiple secondary data in the spatial estimate with the cokriging system. We will cover this later.\n",
    "* **Smoothing effect** of kriging can be forecast. We will use this to build stochastic simulations later.\n",
    "\n",
    "#### Spatial Continuity \n",
    "\n",
    "**Spatial Continuity** is the correlation between values over distance.\n",
    "\n",
    "* No spatial continuity â€“ no correlation between values over distance, random values at each location in space regardless of separation distance.\n",
    "\n",
    "* Homogenous phenomenon have perfect spatial continuity, since all values as the same (or very similar) they are correlated. \n",
    "\n",
    "We need a statistic to quantify spatial continuity! A convenient method is the Semivariogram.\n",
    "\n",
    "#### The Semivariogram\n",
    "\n",
    "Function of difference over distance.\n",
    "\n",
    "* The expected (average) squared difference between values separated by a lag distance vector (distance and direction), $h$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\gamma(\\bf{h}) = \\frac{1}{2 N(\\bf{h})} \\sum^{N(\\bf{h})}_{\\alpha=1} (z(\\bf{u}_\\alpha) - z(\\bf{u}_\\alpha + \\bf{h}))^2  \n",
    "\\end{equation}\n",
    "\n",
    "where $z(\\bf{u}_\\alpha)$ and $z(\\bf{u}_\\alpha + \\bf{h})$ are the spatial sample values at tail and head locations of the lag vector respectively.\n",
    "\n",
    "* Calculated over a suite of lag distances to obtain a continuous function.\n",
    "\n",
    "* the $\\frac{1}{2}$ term converts a variogram into a semivariogram, but in practice the term variogram is used instead of semivariogram.\n",
    "* We prefer the semivariogram because it relates directly to the covariance function, $C_x(\\bf{h})$ and univariate variance, $\\sigma^2_x$:\n",
    "\n",
    "\\begin{equation}\n",
    "C_x(\\bf{h}) = \\sigma^2_x - \\gamma(\\bf{h})\n",
    "\\end{equation}\n",
    "\n",
    "Note the correlogram is related to the covariance function as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_x(\\bf{h}) = \\frac{C_x(\\bf{h})}{\\sigma^2_x}\n",
    "\\end{equation}\n",
    "\n",
    "The correlogram provides of function of the $\\bf{h}-\\bf{h}$ scatter plot correlation vs. lag offset $\\bf{h}$.  \n",
    "\n",
    "\\begin{equation}\n",
    "-1.0 \\le \\rho_x(\\bf{h}) \\le 1.0\n",
    "\\end{equation}\n",
    "\n",
    "#### Objective \n",
    "\n",
    "In the PGE 383: Stochastic Subsurface Modeling class I want to provide hands-on experience with building subsurface modeling workflows. Python provides an excellent vehicle to accomplish this. I have coded a package called GeostatsPy with GSLIB: Geostatistical Library (Deutsch and Journel, 1998) functionality that provides basic building blocks for building subsurface modeling workflows. \n",
    "\n",
    "The objective is to remove the hurdles of subsurface modeling workflow construction by providing building blocks and sufficient examples. This is not a coding class per se, but we need the ability to 'script' workflows working with numerical methods.    \n",
    "\n",
    "#### Getting Started\n",
    "\n",
    "Here's the steps to get setup in Python with the GeostatsPy package:\n",
    "\n",
    "1. Install Anaconda 3 on your machine (https://www.anaconda.com/download/). \n",
    "2. From Anaconda Navigator (within Anaconda3 group), go to the environment tab, click on base (root) green arrow and open a terminal. \n",
    "3. In the terminal type: pip install geostatspy. \n",
    "4. Open Jupyter and in the top block get started by copy and pasting the code block below from this Jupyter Notebook to start using the geostatspy functionality. \n",
    "\n",
    "You will need to copy the data file to your working directory.  They are available here:\n",
    "\n",
    "* Tabular data - sample_data.csv at https://git.io/fh4gm.\n",
    "\n",
    "There are exampled below with these functions. You can go here to see a list of the available functions, https://git.io/fh4eX, other example workflows and source code. \n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "The following code loads the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geostatspy.GSLIB as GSLIB                       # GSLIB utilies, visualization and wrapper\n",
    "import geostatspy.geostats as geostats                 # GSLIB methods convert to Python    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need some standard packages. These should have been installed with Anaconda 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os                                               # to set current working directory \n",
    "import sys                                              # supress output to screen for interactive variogram modeling\n",
    "import io\n",
    "import numpy as np                                      # arrays and matrix math\n",
    "import pandas as pd                                     # DataFrames\n",
    "import matplotlib.pyplot as plt                         # plotting\n",
    "from matplotlib.pyplot import cm                        # color maps\n",
    "from matplotlib.patches import Ellipse                  # plot an ellipse\n",
    "import math                                             # sqrt operator\n",
    "from scipy.stats import norm\n",
    "from ipywidgets import interactive                      # widgets and interactivity\n",
    "from ipywidgets import widgets                            \n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Label\n",
    "from ipywidgets import VBox, HBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing 'python -m pip install [package-name]'. More assistance is available with the respective package docs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple, Simple Kriging Function\n",
    "\n",
    "Let's write a fast Python function to take data points and unknown location and provide the:\n",
    "\n",
    "* **simple kriging estimate**\n",
    "\n",
    "* **simple kriging variance / estimation variance**\n",
    "\n",
    "* **simple kriging weights**\n",
    "\n",
    "This provides a fast method for small datasets, with less parameters (no search parameters) and the ability to see the simple kriging weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_simple_krige(df,xcol,ycol,vcol,dfl,xlcol,ylcol,vario,skmean):\n",
    "# load the variogram\n",
    "    nst = vario['nst']; pmx = 9999.9\n",
    "    cc = np.zeros(nst); aa = np.zeros(nst); it = np.zeros(nst)\n",
    "    ang = np.zeros(nst); anis = np.zeros(nst)\n",
    "    nug = vario['nug']; sill = nug \n",
    "    cc[0] = vario['cc1']; sill = sill + cc[0]\n",
    "    it[0] = vario['it1']; ang[0] = vario['azi1']; \n",
    "    aa[0] = vario['hmaj1']; anis[0] = vario['hmin1']/vario['hmaj1'];\n",
    "    if nst == 2:\n",
    "        cc[1] = vario['cc2']; sill = sill + cc[1]\n",
    "        it[1] = vario['it2']; ang[1] = vario['azi2']; \n",
    "        aa[1] = vario['hmaj2']; anis[1] = vario['hmin2']/vario['hmaj2'];    \n",
    "\n",
    "# set up the required matrices\n",
    "    rotmat, maxcov = geostats.setup_rotmat(nug,nst,it,cc,ang,pmx)    \n",
    "    ndata = len(df); a = np.zeros([ndata,ndata]); r = np.zeros(ndata); s = np.zeros(ndata); rr = np.zeros(ndata)\n",
    "    nest = len(dfl)\n",
    "\n",
    "    est = np.zeros(nest); var = np.full(nest,sill); weights = np.zeros([nest,ndata])\n",
    "\n",
    "# Make and solve the kriging matrix, calculate the kriging estimate and variance \n",
    "    for iest in range(0,nest):\n",
    "        for idata in range(0,ndata):\n",
    "            for jdata in range(0,ndata):\n",
    "                a[idata,jdata] = geostats.cova2(df[xcol].values[idata],df[ycol].values[idata],df[xcol].values[jdata],df[ycol].values[jdata],\n",
    "                                        nst,nug,pmx,cc,aa,it,ang,anis,rotmat,maxcov)\n",
    "            r[idata] = geostats.cova2(df[xcol].values[idata],df[ycol].values[idata],dfl[xlcol].values[iest],dfl[ylcol].values[iest],\n",
    "                                        nst,nug,pmx,cc,aa,it,ang,anis,rotmat,maxcov)\n",
    "            rr[idata] = r[idata]\n",
    "        \n",
    "        s = geostats.ksol_numpy(ndata,a,r)    \n",
    "        sumw = 0.0\n",
    "        for idata in range(0,ndata):                          \n",
    "            sumw = sumw + s[idata]\n",
    "            weights[iest,idata] = s[idata]\n",
    "            est[iest] = est[iest] + s[idata]*df[vcol].values[idata]\n",
    "            var[iest] = var[iest] - s[idata]*rr[idata]\n",
    "        est[iest] = est[iest] + (1.0-sumw)*skmean\n",
    "    return est,var,weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Spatial Problem\n",
    "\n",
    "Here you can specify the values of the 3 data samples (v1, v2, v3) and the global mean (vmean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 25.0                                               # value of sample data #1\n",
    "v2 = 43.0                                               # value of sample data #1                                                  \n",
    "v3 = 56.0                                               # value of sample data #1 \n",
    "value = [v1,v2,v3]                                      # make a data value list\n",
    "vmean = 38.0                                            # value of the global mean for simple kriging\n",
    "sill = 25.0                                             # sill, variance of the dataset                                 \n",
    "vmin = np.min(value) - 3 * np.sqrt(sill)                # minimum value for plotting\n",
    "vmax = np.max(value) + 3 * np.sqrt(sill)                # maximum value for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Simple Kriging Method\n",
    "\n",
    "The following code includes:\n",
    "\n",
    "* dashboard with variogram model data locations \n",
    "\n",
    "* plots of variogram model, data locations with point scaled by weights and uncertainty distribution at the unknown location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# interactive calculation of the sample set (control of source parametric distribution and number of samples)\n",
    "style = {'description_width': 'initial'}\n",
    "l = widgets.Text(value='                                              Simple Kriging, Michael Pyrcz, Associate Professor, The University of Texas at Austin',layout=Layout(width='950px', height='30px'))\n",
    "nug = widgets.FloatSlider(min = 0, max = 1.0, value = 0.0, step = 0.1, description = '$c_{nug}$',orientation='vertical',\n",
    "                          layout=Layout(width='25px', height='218px'))\n",
    "nug.style.handle_color = 'gray'\n",
    "it1 = widgets.Dropdown(options=['Spherical', 'Exponential', 'Gaussian'],value='Spherical',\n",
    "    description='Type:',disabled=False,layout=Layout(width='180px', height='30px'), style=style,continuous_update=False)\n",
    "\n",
    "azi = widgets.FloatSlider(min=0, max = 360, value = 0, step = 22.5, description = '$Azi$',\n",
    "                        orientation='vertical',layout=Layout(width='40px', height='218px'),continuous_update=False)\n",
    "azi.style.handle_color = 'gray'\n",
    "hmaj1 = widgets.FloatSlider(min=0.01, max = 10000.0, value = 100.0, step = 25.0, description = '$a_{maj}$',\n",
    "                        orientation='vertical',layout=Layout(width='40px', height='218px'),continuous_update=False)\n",
    "hmaj1.style.handle_color = 'gray'\n",
    "hmin1 = widgets.FloatSlider(min = 0.01, max = 10000.0, value = 100.0, step = 25.0, description = '$a_{min}$',\n",
    "                        orientation='vertical',layout=Layout(width='40px', height='218px'),continuous_update=False)\n",
    "hmin1.style.handle_color = 'gray'\n",
    "uikvar = widgets.HBox([nug,it1,azi,hmaj1,hmin1],)                   # basic widget formatting   \n",
    "\n",
    "x1 = widgets.FloatSlider(min=0.0, max = 1000.0, value = 100.0, step = 1.0, description = '$x_1$',orientation='horizontal',\n",
    "                         layout=Layout(width='150px', height='30px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "x1.style.handle_color = 'blue'\n",
    "y1 = widgets.FloatSlider(min=0.0, max = 1000.0, value = 200.0, step = 1.0, description = '$y_1$',orientation='vertical',\n",
    "                         layout=Layout(width='70px', height='180px',margin='0 0 0 10px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "y1.style.handle_color = 'blue'\n",
    "uik1 = widgets.VBox([x1,y1],)\n",
    "\n",
    "x2 = widgets.FloatSlider(min=0.0, max = 1000.0, value = 500.0, step = 1.0, description = '$x_2$',orientation='horizontal',\n",
    "                         layout=Layout(width='150px', height='30px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "x2.style.handle_color = 'red'\n",
    "y2 = widgets.FloatSlider(min=0.0, max = 1000.0, value = 800.0, step = 1.0, description = '$y_2$',orientation='vertical',\n",
    "                         layout=Layout(width='70px', height='180px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "y2.style.handle_color = 'red'\n",
    "uik2 = widgets.VBox([x2,y2],)\n",
    "\n",
    "x3 = widgets.FloatSlider(min=0.0, max = 1000.0, value = 700.0, step = 1.0, description = '$x_3$',orientation='horizontal',\n",
    "                         layout=Layout(width='150px', height='30px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "x3.style.handle_color = 'green'\n",
    "y3 = widgets.FloatSlider(min=0.0, max = 1000.0, value = 200.0, step = 1.0, description = '$y_3$',orientation='vertical',\n",
    "                         layout=Layout(width='70px', height='180px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "y3.style.handle_color = 'green'\n",
    "uik3 = widgets.VBox([x3,y3],)\n",
    "\n",
    "xu = widgets.FloatSlider(min=0.0, max = 1000.0, value = 500.0, step = 1.0, description = '$x_0$',orientation='horizontal',\n",
    "                         layout=Layout(width='150px', height='30px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "xu.style.handle_color = 'gray'\n",
    "yu = widgets.FloatSlider(min=0.0, max = 1000.0, value = 500.0, step = 1.0, description = '$y_0$',orientation='vertical',\n",
    "                         layout=Layout(width='70px', height='180px'),readout_format = '.0f',style=style,continuous_update=False)\n",
    "yu.style.handle_color = 'gray'\n",
    "uiku = widgets.VBox([xu,yu],)\n",
    "\n",
    "uipars = widgets.HBox([uikvar,uik1,uik2,uik3,uiku],) \n",
    "uik = widgets.VBox([l,uipars],)\n",
    "\n",
    "def convert_type(it):\n",
    "    if it == 'Spherical': \n",
    "        return 1\n",
    "    elif it == 'Exponential':\n",
    "        return 2\n",
    "    else: \n",
    "        return 3\n",
    "\n",
    "def f_make_krige(nug,it1,azi,hmaj1,hmin1,x1,y1,x2,y2,x3,y3,xu,yu,): # function to take parameters, make sample and plot\n",
    "    text_trap = io.StringIO()\n",
    "    sys.stdout = text_trap\n",
    "    it1 = convert_type(it1)\n",
    "    nst = 1; xlag = 10; nlag = int(hmaj1/xlag); c1 = 1.0-nug\n",
    "    vario = GSLIB.make_variogram(nug,nst,it1,c1,azi,hmaj1,hmin1) # make model object\n",
    "    index_maj,h_maj,gam_maj,cov_maj,ro_maj = geostats.vmodel(nlag,xlag,azi,vario)   # project the model in the major azimuth                                                  # project the model in the 135 azimuth\n",
    "    index_min,h_min,gam_min,cov_min,ro_min = geostats.vmodel(nlag,xlag,azi+90.0,vario) # project the model in the minor azimuth\n",
    "    \n",
    "    clist = ['blue','red','green']\n",
    "    x = [x1,x2,x3]; y = [y1,y2,y3];  \n",
    "    df = pd.DataFrame({'X':x,'Y':y,'Value':value})\n",
    "\n",
    "    xl = [xu,0,1]; yl = [yu,0,1]; value1 = [0,0,0]\n",
    "    dfl = pd.DataFrame({'X':xl,'Y':yl, 'Value':value1})\n",
    "     \n",
    "    sk_est, sk_var, sk_weights =  simple_simple_krige(df,'X','Y','Value',dfl,'X','Y',vario,skmean=vmean)\n",
    "    if sk_var[0] == 0:                                       # sk_std is used for plotting only, leave with sill = 1.0\n",
    "        sk_std = 0.0\n",
    "    else:\n",
    "        sk_std = math.sqrt(sk_var[0])\n",
    "    sk_var[0] = sk_var[0]*sill    \n",
    "    xlag = 10.0; nlag = int(hmaj1/xlag)\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot([0,hmaj1*1.5],[1.0,1.0],color = 'black')\n",
    "    plt.plot(h_maj,gam_maj,color = 'black',label = 'Major ' + str(azi))    \n",
    "    plt.plot(h_min,gam_min,color = 'black',label = 'Minor ' + str(azi+90.0))\n",
    "    deltas = [22.5, 45, 67.5]; \n",
    "    ndelta = len(deltas); hd = np.zeros(ndelta); gamd = np.zeros(ndelta);\n",
    "    color=iter(cm.plasma(np.linspace(0,1,ndelta)))\n",
    "    for delta in deltas:\n",
    "        index,hd,gamd,cov,ro = geostats.vmodel(nlag,xlag,azi+delta,vario);\n",
    "        c=next(color)\n",
    "        plt.plot(hd,gamd,color = c,label = 'Azi ' + str(azi+delta))\n",
    "    plt.xlabel(r'Lag Distance $\\bf(h)$, (m)')\n",
    "    plt.ylabel(r'$\\gamma \\bf(h)$')\n",
    "    plt.title('Interpolated NSCORE Porosity Variogram Models')\n",
    "    plt.xlim([0,hmaj1*1.5])\n",
    "    plt.ylim([0,1.4])\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "        \n",
    "    ax = plt.gca()\n",
    "    plt.xlabel('X(m)'); plt.ylabel('Y(m)')\n",
    "    plt.title('Simple Kriging - Data and Unknown Locations')\n",
    "    plt.xlim([0,1000])\n",
    "    plt.ylim([0,1000])\n",
    "    for i, txt in enumerate(np.round(sk_weights[0],2)):\n",
    "        plt.annotate('$\\lambda$' + ' ' + '$=$' + str(txt), (x[i]+20, y[i]+20),color = clist[i])\n",
    "        plt.annotate(i+1, (x[i]+46, y[i]+15),fontsize=6,color = clist[i])\n",
    "    for i, txt in enumerate(value):\n",
    "        plt.annotate('$z(\\mathbf{u}$' + ' ' + '$ )$  = ' + str(txt), (x[i]+20, y[i]-40),color = clist[i])\n",
    "        plt.annotate(i+1, (x[i]+80, y[i]-45),fontsize=6,color = clist[i])\n",
    "    plt.annotate('$\\sum \\lambda_{\\\\alpha} = $'+ str(np.round(np.sum(sk_weights[0]),2)), (xu+20, yu+20))\n",
    "    plt.annotate('$z^*(\\mathbf{u}_0)$ = '+ str(np.round(sk_est[0],2)), (xu+20, yu-40))\n",
    "    plt.annotate('Mean Weight = ' + str(np.round(1.0 - np.sum(sk_weights[0]),2)), (20, 20))\n",
    "    plt.annotate('?', (xu-20, yu + 30))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ellipse = Ellipse((xu, yu),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='gray',alpha = 0.1,edgecolor='black',zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    ellipse = Ellipse((xu, yu),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='none',alpha = 1.0,edgecolor='black',zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    #ellipse = Ellipse((x1, y1),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='blue',alpha = 0.1,zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    #ellipse = Ellipse((x1, y1),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='none',alpha = 1.0,edgecolor='blue',zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    #ellipse = Ellipse((x2, y2),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='red',alpha = 0.1,zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    #ellipse = Ellipse((x2, y2),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='none',alpha = 1.0,edgecolor='red',zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    #ellipse = Ellipse((x3, y3),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='green',alpha = 0.1,zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "    #ellipse = Ellipse((x3, y3),width=hmin1*2.0,height=hmaj1*2.0,angle = 360-azi,facecolor='none',alpha = 1.0,edgecolor='green',zorder=10)\n",
    "    ax.add_patch(ellipse)\n",
    "   \n",
    "    if sk_weights[0,0] > 0.01:\n",
    "        plt.scatter(x1,y1,color = 'blue', edgecolors = 'black', s = sk_weights[0,0]*1000, alpha = 0.3,zorder=100)\n",
    "    else:\n",
    "        plt.scatter(x1,y1,color = 'blue', edgecolors = 'black', marker = 'x', alpha = 0.3,zorder=100)\n",
    "    if sk_weights[0,1] > 0.01:    \n",
    "        plt.scatter(x2,y2,color = 'red', edgecolors = 'black', s = sk_weights[0,1]*1000,alpha = 0.3,zorder=100)\n",
    "    else:\n",
    "        plt.scatter(x2,y2,color = 'red', edgecolors = 'black', marker = 'x',alpha = 0.3,zorder=100)\n",
    "    if sk_weights[0,2] > 0.01:\n",
    "        plt.scatter(x3,y3,color = 'green', edgecolors = 'black', s = sk_weights[0,2]*1000, alpha = 0.3,zorder=100)\n",
    "    else:\n",
    "        plt.scatter(x3,y3,color = 'green', edgecolors = 'black', marker = 'x', alpha = 0.3,zorder=100)\n",
    "       \n",
    "    if (1-sk_std) > 0.01:\n",
    "        scatter = plt.scatter(xu,yu,color = 'gray', edgecolors = 'black', s = (1-sk_std)*1000,alpha = 0.3,zorder=100)\n",
    "    else: \n",
    "        scatter = plt.scatter(xu,yu,color = 'black', edgecolors = 'black', marker = 'x', alpha = 0.3,zorder=100)\n",
    "\n",
    "    samples = norm.rvs(sk_est[0],math.sqrt(sk_var[0]),1000,random_state=73073)   \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.hist(samples,histtype = 'stepfilled',cumulative = True, bins = np.linspace(vmin,vmax,200),alpha=0.8,color=\"darkorange\",edgecolor='black',density=True)\n",
    "    plt.xlim([vmin,vmax]); plt.ylim([0,1.0])\n",
    "    plt.title('Kriging Uncertainty Model at Unknown Location')\n",
    "    plt.xlabel('Value'); plt.ylabel('Frequency')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.annotate(r'$z^*(\\mathbf{u}_0)$ = ' + str(np.round(sk_est[0],2)), (0.05*(vmax-vmin)+vmin, 0.9))\n",
    "    ax.annotate(r'$\\sigma_z^2(\\mathbf{u}_0)$ = ' + str(np.round(sk_var[0],2)), (0.05*(vmax-vmin)+vmin, 0.83))\n",
    "    ax.annotate(r'$P10_z(\\mathbf{u}_0)$ = ' + str(np.round(np.percentile(samples,10),2)), (0.05*(vmax-vmin)+vmin, 0.76))\n",
    "    ax.annotate(r'$P90_z(\\mathbf{u}_0)$ = ' + str(np.round(np.percentile(samples,90),2)), (0.05*(vmax-vmin)+vmin, 0.69))\n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=2.2, top=0.9, wspace=0.3, hspace=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "# connect the function to make the samples and plot to the widgets    \n",
    "interactive_plot = widgets.interactive_output(f_make_krige, {'nug':nug, 'it1':it1, 'azi':azi, 'hmaj1':hmaj1, 'hmin1':hmin1, \n",
    "                                                      'x1':x1, 'y1':y1, 'x2':x2, 'y2':y2, 'x3':x3, 'y3':y3, 'xu':xu, 'yu':yu})\n",
    "interactive_plot.clear_output(wait = True)               # reduce flickering by delaying plot updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Simple Kriging Demostration\n",
    "\n",
    "* select the variogram model and the data locations and observe the outputs from simple kriging \n",
    "\n",
    "#### Michael Pyrcz, Associate Professor, University of Texas at Austin \n",
    "\n",
    "##### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1) | [GeostatsPy](https://github.com/GeostatsGuy/GeostatsPy)\n",
    "\n",
    "### The Inputs\n",
    "\n",
    "Select the variogram model and the data locations:\n",
    "\n",
    "* **nug**: nugget effect\n",
    "\n",
    "* **c1 **: contributions of the sill\n",
    "\n",
    "* **hmaj1 / hmin1 **: range in the major and minor direction\n",
    "\n",
    "* **(x1, y1),...(x3,y3) **: spatial data locations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f6d14eda2e4f43ba2e882c78655a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='                                              Simple Kriging, Michael Pyrcz, Associâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dc7a6b282d4d419758605fdbad5e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 432x288 with 3 Axes>', 'iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(uik, interactive_plot)                            # display the interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "This was an interactive demonstration of simple kriging for spatial data analytics. Much more could be done, I have other demonstrations on the basics of working with DataFrames, ndarrays, univariate statistics, plotting data, declustering, data transformations and many other workflows available at https://github.com/GeostatsGuy/PythonNumericalDemos and https://github.com/GeostatsGuy/GeostatsPy. \n",
    "  \n",
    "#### The Author:\n",
    "\n",
    "### Michael Pyrcz, Associate Professor, University of Texas at Austin \n",
    "*Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions*\n",
    "\n",
    "With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers' and geoscientists' impact in subsurface resource development. \n",
    "\n",
    "For more about Michael check out these links:\n",
    "\n",
    "#### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "#### Want to Work Together?\n",
    "\n",
    "I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.\n",
    "\n",
    "* Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I'd be happy to drop by and work with you! \n",
    "\n",
    "* Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster, Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!\n",
    "\n",
    "* I can be reached at mpyrcz@austin.utexas.edu.\n",
    "\n",
    "I'm always happy to discuss,\n",
    "\n",
    "*Michael*\n",
    "\n",
    "Michael Pyrcz, Ph.D., P.Eng. Associate Professor The Hildebrand Department of Petroleum and Geosystems Engineering, Bureau of Economic Geology, The Jackson School of Geosciences, The University of Texas at Austin\n",
    "\n",
    "#### More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
